{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlNVzQVYbyfvpRyV9+iw3m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wisdomscode/AI-Lab-Deep-Learning-PyTorch/blob/main/AI_Lab_Project2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7_2P0leYcho"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common Errors In PyTorch Sequential Models\n"
      ],
      "metadata": {
        "id": "Vj0Ffw4EYmyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch's `nn.Sequential` offers a streamlined method for constructing neural networks. This sequential approach is particularly effective for crafting straightforward architectures where each layer directly feeds into the subsequent one. However, when building these models, it's crucial to exercise caution, as inadvertent layer sizing issues can result in runtime errors or unexpected model behavior.\n",
        "\n",
        "We'll consider the following common error scenarios when constructing a PyTorch Sequential model:\n",
        "\n",
        "* Incorrect layer sizing, both in the input layer and after flattening a convolutional layer\n",
        "* Accidental layer duplication\n",
        "* Forgetting to flatten between convolutional and linear layers\n",
        "These scenarios will emphasize the importance of paying careful attention and verification when creating neural network architectures."
      ],
      "metadata": {
        "id": "S15GiP9cYtpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Error Caused By Incorrect Input Layer Size"
      ],
      "metadata": {
        "id": "uO5ZimqMZAdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with imports, then define and run a PyTorch model."
      ],
      "metadata": {
        "id": "6zZwtUwFZI6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "2ERqt-4AZJiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "model = torch.nn.Sequential()\n",
        "linear1 = nn.Linear(in_features=3200, out_features=128)\n",
        "model.append(linear1)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(torch.nn.Dropout())\n",
        "linear2 = nn.Linear(in_features=128, out_features=64)\n",
        "model.append(linear2)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(torch.nn.Dropout())\n",
        "linear3 = nn.Linear(in_features=64, out_features=10)\n",
        "model.append(linear3)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(torch.nn.Dropout())\n",
        "print(model)\n",
        "\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(size=(32, 100))\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "\n",
        "# Run the model\n",
        "output = model(input_tensor)\n",
        "print(\"Output shape:\", output.shape)\n",
        "\n",
        "\n",
        "# output\n",
        "Sequential(\n",
        "  (0): Linear(in_features=3200, out_features=128, bias=True)\n",
        "  (1): ReLU()\n",
        "  (2): Dropout(p=0.5, inplace=False)\n",
        "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
        "  (4): ReLU()\n",
        "  (5): Dropout(p=0.5, inplace=False)\n",
        "  (6): Linear(in_features=64, out_features=10, bias=True)\n",
        "  (7): ReLU()\n",
        "  (8): Dropout(p=0.5, inplace=False)\n",
        ")\n",
        "Input shape: torch.Size([32, 100])\n",
        "\n",
        "# Error Message\n",
        "---------------------------------------------------------------------------\n",
        "RuntimeError                              Traceback (most recent call last)\n",
        "Cell In[4], line 22\n",
        "     19 print(\"Input shape:\", input_tensor.shape)\n",
        "     21 # Run the model\n",
        "---> 22 output = model(input_tensor)\n",
        "     23 print(\"Output shape:\", output.shape)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511, in Module._wrapped_call_impl(self, *args, **kwargs)\n",
        "   1509     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
        "   1510 else:\n",
        "-> 1511     return self._call_impl(*args, **kwargs)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520, in Module._call_impl(self, *args, **kwargs)\n",
        "   1515 # If we don't have any hooks, we want to skip the rest of the logic in\n",
        "   1516 # this function, and just call forward.\n",
        "   1517 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
        "   1518         or _global_backward_pre_hooks or _global_backward_hooks\n",
        "   1519         or _global_forward_hooks or _global_forward_pre_hooks):\n",
        "-> 1520     return forward_call(*args, **kwargs)\n",
        "   1522 try:\n",
        "   1523     result = None\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/container.py:217, in Sequential.forward(self, input)\n",
        "    215 def forward(self, input):\n",
        "    216     for module in self:\n",
        "--> 217         input = module(input)\n",
        "    218     return input\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511, in Module._wrapped_call_impl(self, *args, **kwargs)\n",
        "   1509     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
        "   1510 else:\n",
        "-> 1511     return self._call_impl(*args, **kwargs)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520, in Module._call_impl(self, *args, **kwargs)\n",
        "   1515 # If we don't have any hooks, we want to skip the rest of the logic in\n",
        "   1516 # this function, and just call forward.\n",
        "   1517 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
        "   1518         or _global_backward_pre_hooks or _global_backward_hooks\n",
        "   1519         or _global_forward_hooks or _global_forward_pre_hooks):\n",
        "-> 1520     return forward_call(*args, **kwargs)\n",
        "   1522 try:\n",
        "   1523     result = None\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/linear.py:116, in Linear.forward(self, input)\n",
        "    115 def forward(self, input: Tensor) -> Tensor:\n",
        "--> 116     return F.linear(input, self.weight, self.bias)\n",
        "\n",
        "RuntimeError: mat1 and mat2 shapes cannot be multiplied (32x100 and 3200x128)"
      ],
      "metadata": {
        "id": "G4KcPSPNZh9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code execution fails, resulting in a `RuntimeError`. When interpreting a Python stack trace, always begin at the **bottom** and work your way **up**. PyTorch errors are typically more verbose than standard Python errors. In this instance, we're encountering a `RuntimeError`, signaling an issue during model execution. Scanning **upwards**, we find the line `output = model(input_tensor)` near the top. The lower lines in the stack trace show different function calls from the PyTorch library, but they're not the most important part of the error message. The key is to focus on the code that was written in the notebook.\n",
        "\n",
        "The line `output = model(input_tensor)` triggers the error as it feeds the input data to the model for the forward pass. During the forward pass, the model sequentially applies layers and operations to compute output predictions. The failure occurs due to misaligned layer dimensions. The error message provides critical information: `mat1 and mat2 shapes cannot be multiplied (32x100 and 3200x128)`.\n",
        "\n",
        "At the heart of deep learning is matrix algebra. Matrix algebra has very specific rules for matrix multiplication. One crucial rule is that the number of columns in the first matrix (mat1) must equal the number of rows in the second matrix (mat2). This condition is not met in the current input, where the first matrix has 100 columns and the second matrix has 3200 rows.\n",
        "\n",
        "This error commonly stems from incorrectly specifying layer dimensions, particularly in the input layer. The value passed to the `in_features` argument must exactly match the input data dimensions. Dimensional mismatches often lead to runtime errors or unexpected model behavior.\n",
        "\n",
        "To resolve this issue, let's carefully review the code to identify the dimensional inconsistency. Printing the shape of the model and data can help debugging. This error can be fixed by adjusting the first layer to `in_features=100`, thus matching the size of the input tensor. Let's define another version of the model with that change."
      ],
      "metadata": {
        "id": "iSKEaIfDcX15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a revised model\n",
        "model = torch.nn.Sequential()\n",
        "linear1 = nn.Linear(\n",
        "    in_features=100, out_features=128\n",
        ")  # This line was changed to match input size\n",
        "model.append(linear1)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(torch.nn.Dropout())\n",
        "linear2 = nn.Linear(in_features=128, out_features=64)\n",
        "model.append(linear2)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(torch.nn.Dropout())\n",
        "linear3 = nn.Linear(in_features=64, out_features=10)\n",
        "model.append(linear3)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(torch.nn.Dropout())\n",
        "print(model)\n",
        "\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(size=(32, 100))\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "\n",
        "# Run the model\n",
        "output = model(input_tensor)\n",
        "print(\"Output shape:\", output.shape)\n",
        "\n",
        "# output\n",
        "Sequential(\n",
        "  (0): Linear(in_features=100, out_features=128, bias=True)\n",
        "  (1): ReLU()\n",
        "  (2): Dropout(p=0.5, inplace=False)\n",
        "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
        "  (4): ReLU()\n",
        "  (5): Dropout(p=0.5, inplace=False)\n",
        "  (6): Linear(in_features=64, out_features=10, bias=True)\n",
        "  (7): ReLU()\n",
        "  (8): Dropout(p=0.5, inplace=False)\n",
        ")\n",
        "Input shape: torch.Size([32, 100])\n",
        "Output shape: torch.Size([32, 10])"
      ],
      "metadata": {
        "id": "gSXu3Bw6cYtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error Caused By Adding The Same Layer Twice"
      ],
      "metadata": {
        "id": "OyLf9xb1cn6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build another PyTorch model, this time a Convolutional Neural Network (CNN)."
      ],
      "metadata": {
        "id": "TLqXSvwgdLCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "model = torch.nn.Sequential()\n",
        "conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
        "model.append(conv1)\n",
        "model.append(torch.nn.ReLU())\n",
        "max_pool1 = nn.MaxPool2d(2, 2)\n",
        "model.append(max_pool1)\n",
        "model.append(conv1)  # Add the same layer again\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(max_pool1)\n",
        "print(model)\n",
        "\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "\n",
        "# Run the model\n",
        "output = model(input_tensor)\n",
        "print(\"Output shape:\", output.shape)\n",
        "\n",
        "# output\n",
        "Sequential(\n",
        "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  (1): ReLU()\n",
        "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "  (3): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  (4): ReLU()\n",
        "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        ")\n",
        "Input shape: torch.Size([1, 3, 224, 224])\n",
        "\n",
        "# Error Message\n",
        "---------------------------------------------------------------------------\n",
        "RuntimeError                              Traceback (most recent call last)\n",
        "Cell In[9], line 18\n",
        "     15 print(\"Input shape:\", input_tensor.shape)\n",
        "     17 # Run the model\n",
        "---> 18 output = model(input_tensor)\n",
        "     19 print(\"Output shape:\", output.shape)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511, in Module._wrapped_call_impl(self, *args, **kwargs)\n",
        "   1509     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
        "   1510 else:\n",
        "-> 1511     return self._call_impl(*args, **kwargs)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520, in Module._call_impl(self, *args, **kwargs)\n",
        "   1515 # If we don't have any hooks, we want to skip the rest of the logic in\n",
        "   1516 # this function, and just call forward.\n",
        "   1517 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
        "   1518         or _global_backward_pre_hooks or _global_backward_hooks\n",
        "   1519         or _global_forward_hooks or _global_forward_pre_hooks):\n",
        "-> 1520     return forward_call(*args, **kwargs)\n",
        "   1522 try:\n",
        "   1523     result = None\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/container.py:217, in Sequential.forward(self, input)\n",
        "    215 def forward(self, input):\n",
        "    216     for module in self:\n",
        "--> 217         input = module(input)\n",
        "    218     return input\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511, in Module._wrapped_call_impl(self, *args, **kwargs)\n",
        "   1509     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
        "   1510 else:\n",
        "-> 1511     return self._call_impl(*args, **kwargs)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520, in Module._call_impl(self, *args, **kwargs)\n",
        "   1515 # If we don't have any hooks, we want to skip the rest of the logic in\n",
        "   1516 # this function, and just call forward.\n",
        "   1517 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
        "   1518         or _global_backward_pre_hooks or _global_backward_hooks\n",
        "   1519         or _global_forward_hooks or _global_forward_pre_hooks):\n",
        "-> 1520     return forward_call(*args, **kwargs)\n",
        "   1522 try:\n",
        "   1523     result = None\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/conv.py:460, in Conv2d.forward(self, input)\n",
        "    459 def forward(self, input: Tensor) -> Tensor:\n",
        "--> 460     return self._conv_forward(input, self.weight, self.bias)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456, in Conv2d._conv_forward(self, input, weight, bias)\n",
        "    452 if self.padding_mode != 'zeros':\n",
        "    453     return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
        "    454                     weight, bias, self.stride,\n",
        "    455                     _pair(0), self.dilation, self.groups)\n",
        "--> 456 return F.conv2d(input, weight, bias, self.stride,\n",
        "    457                 self.padding, self.dilation, self.groups)\n",
        "\n",
        "RuntimeError: Given groups=1, weight of size [16, 3, 3, 3], expected input[1, 16, 112, 112] to have 3 channels, but got 16 channels instead"
      ],
      "metadata": {
        "id": "5TEPNx-TceSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the cell is executed, it also generates a `RuntimeError`. The message \"Given groups=1, weight of size [16, 3, 3, 3], expected input[1, 16, 224, 224] to have 3 channels, but got 16 channels instead\" is a clue that the dimensions do not line up correctly. That is caused because the same layer was accidentally added twice to a model. This is typically caused by a copy-and-paste mistake.\n",
        "\n",
        "To resolve this issue, you'll need to carefully review your code and identify where this dimensional inconsistency occurs. Pay particular attention to the layer where you might have accidentally duplicated a component, leading to unexpected channel dimensions."
      ],
      "metadata": {
        "id": "xt4G5JimdJ3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code can be fixed by adding a different layer that has the appropriate dimensions."
      ],
      "metadata": {
        "id": "_T-YUSTfd_eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a revised model\n",
        "model = torch.nn.Sequential()\n",
        "conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
        "model.append(conv1)\n",
        "model.append(torch.nn.ReLU())\n",
        "max_pool1 = nn.MaxPool2d(2, 2)\n",
        "model.append(max_pool1)\n",
        "# Define and add a new layer instead of the same previous one\n",
        "conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "model.append(conv2)\n",
        "model.append(torch.nn.ReLU())\n",
        "max_pool2 = nn.MaxPool2d(2, 2)\n",
        "model.append(max_pool2)\n",
        "print(model)\n",
        "\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "\n",
        "# Run the model\n",
        "output = model(input_tensor)\n",
        "print(\"Output shape:\", output.shape)\n",
        "\n",
        "# output\n",
        "Sequential(\n",
        "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  (1): ReLU()\n",
        "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  (4): ReLU()\n",
        "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        ")\n",
        "Input shape: torch.Size([1, 3, 224, 224])\n",
        "Output shape: torch.Size([1, 32, 56, 56])"
      ],
      "metadata": {
        "id": "K8kbZ5K1eAEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.1.2:** Fix a `RuntimeError` by not adding the same layer twice."
      ],
      "metadata": {
        "id": "2MAvlg7He-pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "model = torch.nn.Sequential()\n",
        "conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=2, padding=1)\n",
        "model.append(conv1)\n",
        "model.append(torch.nn.ReLU())\n",
        "max_pool1 = nn.MaxPool2d(2, 2)\n",
        "model.append(max_pool1)\n",
        "conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
        "model.append(conv2)\n",
        "model.append(torch.nn.ReLU())\n",
        "max_pool2 = nn.MaxPool2d(2, 2)\n",
        "model.append(max_pool2)\n",
        "conv3 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, padding=1)\n",
        "model.append(conv3)\n",
        "model.append(torch.nn.ReLU())\n",
        "max_pool3 = nn.MaxPool2d(2, 2)\n",
        "model.append(max_pool3)\n",
        "conv4 = nn.Conv2d(in_channels=8, out_channels=1, kernel_size=2, padding=1)\n",
        "\n",
        "model.append(conv4)  # fixed the error here by putting conv4 instead of conv3\n",
        "model.append(torch.nn.ReLU())\n",
        "max_pool4 = nn.MaxPool2d(2, 2)\n",
        "model.append(max_pool4)\n",
        "print(model)\n",
        "\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(size=(1, 1, 224, 224))\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "\n",
        "# Run the model\n",
        "output = model(input_tensor)\n",
        "print(\"Output shape:\", output.shape)\n"
      ],
      "metadata": {
        "id": "HM8lt0J8e_Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error Caused By Forgetting to Flatten"
      ],
      "metadata": {
        "id": "FXC1gFfvfWNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's construct another model with multiple convolutional layers (Conv2d) followed by several fully connected layers (Linear)."
      ],
      "metadata": {
        "id": "XMcNNsy6fZW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "model = torch.nn.Sequential()\n",
        "model.append(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1))\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(nn.MaxPool2d(2, 2))\n",
        "model.append(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1))\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(nn.MaxPool2d(2, 2))\n",
        "model.append(nn.Linear(in_features=32 * 56 * 56, out_features=128))\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.Linear(in_features=128, out_features=10))\n",
        "print(model)\n",
        "\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "\n",
        "# Run the model\n",
        "output = model(input_tensor)\n",
        "print(\"Output shape:\", output.shape)\n",
        "\n",
        "# output\n",
        "Sequential(\n",
        "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  (1): ReLU()\n",
        "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  (4): ReLU()\n",
        "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "  (6): Linear(in_features=100352, out_features=128, bias=True)\n",
        "  (7): ReLU()\n",
        "  (8): Linear(in_features=128, out_features=10, bias=True)\n",
        ")\n",
        "Input shape: torch.Size([1, 3, 224, 224])\n",
        "\n",
        "# Error\n",
        "---------------------------------------------------------------------------\n",
        "RuntimeError                              Traceback (most recent call last)\n",
        "Cell In[14], line 19\n",
        "     16 print(\"Input shape:\", input_tensor.shape)\n",
        "     18 # Run the model\n",
        "---> 19 output = model(input_tensor)\n",
        "     20 print(\"Output shape:\", output.shape)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511, in Module._wrapped_call_impl(self, *args, **kwargs)\n",
        "   1509     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
        "   1510 else:\n",
        "-> 1511     return self._call_impl(*args, **kwargs)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520, in Module._call_impl(self, *args, **kwargs)\n",
        "   1515 # If we don't have any hooks, we want to skip the rest of the logic in\n",
        "   1516 # this function, and just call forward.\n",
        "   1517 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
        "   1518         or _global_backward_pre_hooks or _global_backward_hooks\n",
        "   1519         or _global_forward_hooks or _global_forward_pre_hooks):\n",
        "-> 1520     return forward_call(*args, **kwargs)\n",
        "   1522 try:\n",
        "   1523     result = None\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/container.py:217, in Sequential.forward(self, input)\n",
        "    215 def forward(self, input):\n",
        "    216     for module in self:\n",
        "--> 217         input = module(input)\n",
        "    218     return input\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511, in Module._wrapped_call_impl(self, *args, **kwargs)\n",
        "   1509     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
        "   1510 else:\n",
        "-> 1511     return self._call_impl(*args, **kwargs)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520, in Module._call_impl(self, *args, **kwargs)\n",
        "   1515 # If we don't have any hooks, we want to skip the rest of the logic in\n",
        "   1516 # this function, and just call forward.\n",
        "   1517 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
        "   1518         or _global_backward_pre_hooks or _global_backward_hooks\n",
        "   1519         or _global_forward_hooks or _global_forward_pre_hooks):\n",
        "-> 1520     return forward_call(*args, **kwargs)\n",
        "   1522 try:\n",
        "   1523     result = None\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/linear.py:116, in Linear.forward(self, input)\n",
        "    115 def forward(self, input: Tensor) -> Tensor:\n",
        "--> 116     return F.linear(input, self.weight, self.bias)\n",
        "\n",
        "RuntimeError: mat1 and mat2 shapes cannot be multiplied (1792x56 and 100352x128)"
      ],
      "metadata": {
        "id": "LEiQVLgNf_0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon execution, this model generates a `RuntimeError`. Let's analyze this error message as we did in the previous example. Concentrate on the matrix dimension mismatch: \"the mat1 and mat2 shapes cannot be multiplied (7168x224 and 1605632x128)\".\n",
        "\n",
        "The error in the code stems from attempting to feed the output of the max pooling layer (`MaxPool2d`) directly into fully connected layers (`Linear`). This fails because `Conv2d` layers produce a 4D tensor (`batch_size`, `channels`, `height`, `width`), while `Linear` layers expect a 2D tensor (`batch_size`, `features`).\n",
        "\n",
        "To resolve this issue, the tensor needs to be flattened before it enters the fully connected layers. This flattening step transforms the 4D output from the convolutional layers into a 2D tensor that the Linear layers can process. Without this crucial step, the dimensions of the data flowing through your model become incompatible, leading to the observed error.\n",
        "\n",
        "Here is the corrected code that flattens the tensor before passing it to the fully connected layers."
      ],
      "metadata": {
        "id": "Jrxz_Ygigl9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "model = torch.nn.Sequential()\n",
        "model.append(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1))\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(nn.MaxPool2d(2, 2))\n",
        "model.append(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1))\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(nn.MaxPool2d(2, 2))\n",
        "model.append(torch.nn.Flatten())  # Flatten the tensor before passing to Linear layers\n",
        "model.append(nn.Linear(in_features=32 * 56 * 56, out_features=128))\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.Linear(in_features=128, out_features=10))\n",
        "print(model)\n",
        "\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "\n",
        "# Run the model\n",
        "output = model(input_tensor)\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "id": "oTF2KtaxguGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.1.3:** Fix a `RuntimeError` caused by forgetting to flatten."
      ],
      "metadata": {
        "id": "f9YSQp_riu4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "model = torch.nn.Sequential()\n",
        "model.append(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1))\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "model.append(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1))\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "model.append(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1))\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "model.append(torch.nn.Flatten())  # Add this Flatten the tensor before passing to Linear layers\n",
        "model.append(nn.Linear(in_features=64 * 28 * 28, out_features=256)) # can't add this without Flatten first\n",
        "\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.Linear(in_features=256, out_features=64))\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.Linear(in_features=64, out_features=10))\n",
        "print(model)\n",
        "\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "\n",
        "# Run the model\n",
        "output = model(input_tensor)\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "id": "FNQ4VzBcitsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error Caused By Incorrect Layer Size After Flattening"
      ],
      "metadata": {
        "id": "bFUr14Gzi6Vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at another example of convolutional layer followed by a linear layer."
      ],
      "metadata": {
        "id": "Ti6U1jrQi8sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "model = torch.nn.Sequential()\n",
        "model.append(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1))\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(nn.MaxPool2d(2, 2))\n",
        "model.append(torch.nn.Flatten())\n",
        "model.append(nn.Linear(in_features=16 * 224 * 224, out_features=32))\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.Linear(in_features=32, out_features=10))\n",
        "print(model)\n",
        "\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "\n",
        "# Run the model\n",
        "output = model(input_tensor)\n",
        "print(\"Output shape:\", output.shape)\n",
        "\n",
        "# output\n",
        "Sequential(\n",
        "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  (1): ReLU()\n",
        "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "  (3): Flatten(start_dim=1, end_dim=-1)\n",
        "  (4): Linear(in_features=802816, out_features=32, bias=True)\n",
        "  (5): ReLU()\n",
        "  (6): Linear(in_features=32, out_features=10, bias=True)\n",
        ")\n",
        "Input shape: torch.Size([1, 3, 224, 224])\n",
        "\n",
        "# Error output\n",
        "---------------------------------------------------------------------------\n",
        "RuntimeError                              Traceback (most recent call last)\n",
        "Cell In[19], line 17\n",
        "     14 print(\"Input shape:\", input_tensor.shape)\n",
        "     16 # Run the model\n",
        "---> 17 output = model(input_tensor)\n",
        "     18 print(\"Output shape:\", output.shape)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511, in Module._wrapped_call_impl(self, *args, **kwargs)\n",
        "   1509     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
        "   1510 else:\n",
        "-> 1511     return self._call_impl(*args, **kwargs)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520, in Module._call_impl(self, *args, **kwargs)\n",
        "   1515 # If we don't have any hooks, we want to skip the rest of the logic in\n",
        "   1516 # this function, and just call forward.\n",
        "   1517 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
        "   1518         or _global_backward_pre_hooks or _global_backward_hooks\n",
        "   1519         or _global_forward_hooks or _global_forward_pre_hooks):\n",
        "-> 1520     return forward_call(*args, **kwargs)\n",
        "   1522 try:\n",
        "   1523     result = None\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/container.py:217, in Sequential.forward(self, input)\n",
        "    215 def forward(self, input):\n",
        "    216     for module in self:\n",
        "--> 217         input = module(input)\n",
        "    218     return input\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511, in Module._wrapped_call_impl(self, *args, **kwargs)\n",
        "   1509     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
        "   1510 else:\n",
        "-> 1511     return self._call_impl(*args, **kwargs)\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520, in Module._call_impl(self, *args, **kwargs)\n",
        "   1515 # If we don't have any hooks, we want to skip the rest of the logic in\n",
        "   1516 # this function, and just call forward.\n",
        "   1517 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
        "   1518         or _global_backward_pre_hooks or _global_backward_hooks\n",
        "   1519         or _global_forward_hooks or _global_forward_pre_hooks):\n",
        "-> 1520     return forward_call(*args, **kwargs)\n",
        "   1522 try:\n",
        "   1523     result = None\n",
        "\n",
        "File /usr/local/lib/python3.11/site-packages/torch/nn/modules/linear.py:116, in Linear.forward(self, input)\n",
        "    115 def forward(self, input: Tensor) -> Tensor:\n",
        "--> 116     return F.linear(input, self.weight, self.bias)\n",
        "\n",
        "RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x200704 and 802816x32)"
      ],
      "metadata": {
        "id": "DrEhktEOjY7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model generates a `RuntimeError` when attempting to execute the cell due to a matrix dimension mismatch: \"mat1 and mat2 shapes cannot be multiplied (1x200704 and 802816x32).\"\n",
        "\n",
        "The issue arises from incorrectly specifying the size of the linear layer after flattening from a convolutional layer. The code specifies`model.append(nn.Linear(in_features=16 * 224 * 224, out_features=32))`, but the `in_features` value is incorrect. While 16 is the correct number based on the output channels from the `Conv2d` layer, the spatial dimensions should be 112x112 (half of 224x224 due to the `MaxPool2d(2, 2)` layer). The correct value for `in_features` should be 16 * 112 * 112.\n",
        "\n",
        "Let's update the model with this change and try running it again."
      ],
      "metadata": {
        "id": "etsCTy5EkUvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "model = torch.nn.Sequential()\n",
        "model.append(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1))\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(nn.MaxPool2d(2, 2))\n",
        "model.append(torch.nn.Flatten())\n",
        "model.append(\n",
        "    nn.Linear(in_features=16 * 112 * 112, out_features=32)\n",
        ")  # in_features modified to match the expected number of dimensions\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.Linear(in_features=32, out_features=10))\n",
        "print(model)\n",
        "\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "\n",
        "# Run the model\n",
        "output = model(input_tensor)\n",
        "print(\"Output shape:\", output.shape)\n",
        "\n",
        "# output\n",
        "Sequential(\n",
        "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  (1): ReLU()\n",
        "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "  (3): Flatten(start_dim=1, end_dim=-1)\n",
        "  (4): Linear(in_features=200704, out_features=32, bias=True)\n",
        "  (5): ReLU()\n",
        "  (6): Linear(in_features=32, out_features=10, bias=True)\n",
        ")\n",
        "Input shape: torch.Size([1, 3, 224, 224])\n",
        "Output shape: torch.Size([1, 10])"
      ],
      "metadata": {
        "id": "b_KK_md4jbqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.1.4:** Fix a `RuntimeError` caused by incorrect dimensions after flattening."
      ],
      "metadata": {
        "id": "lU3-CDANk_6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "model = torch.nn.Sequential()\n",
        "model.append(\n",
        "    nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        ")\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "model.append(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1))\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "model.append(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1))\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "model.append(nn.Flatten())\n",
        "\n",
        "# model.append(nn.Linear(in_features=128 * 7 * 7, out_features=1000))  # This is wrong\n",
        "model.append(nn.Linear(in_features=256 * 14 * 14, out_features=1000)) # Add this\n",
        "\n",
        "\n",
        "model.append(nn.ReLU())\n",
        "model.append(nn.Linear(in_features=1000, out_features=10))\n",
        "print(model)\n",
        "\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "\n",
        "# Run the model\n",
        "output = model(input_tensor)\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "id": "jaqtWU-qk9_G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}