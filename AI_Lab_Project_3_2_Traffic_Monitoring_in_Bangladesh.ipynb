{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOcTlhfwqCFzIDrbhMb95pj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wisdomscode/AI-Lab-Deep-Learning-PyTorch/blob/main/AI_Lab_Project_3_2_Traffic_Monitoring_in_Bangladesh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Object Detection\n"
      ],
      "metadata": {
        "id": "-T7xSGZX8qwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object detection is a computer vision task that involves identifying and location objects in images or video\n",
        "\n",
        "Challenges of Object detection\n",
        "1. partial or incomplete image\n",
        "2. Overlapping image\n",
        "\n"
      ],
      "metadata": {
        "id": "Gpy2gFfT8yn-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Object Classification vs Object Detection**\n",
        "\n",
        "**Object Classification**\n",
        "\n",
        "Is labelling an entire image with a single class of primary object, it uses single output per image, task is right or wrong predictions of that single label"
      ],
      "metadata": {
        "id": "hifn2n1x_3Q6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Object Detection**\n",
        "\n",
        "Identify, locate and label multiple objects within an image,\n",
        "multiple possible outputs per image\n",
        "More complex, must account for multiple aspects of prediction\n",
        " * Presence of objects\n",
        " * Class of each object\n",
        " * Location of each object in a bounding box\n"
      ],
      "metadata": {
        "id": "e8sjmn918_c_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object Detection Applications\n",
        "1. Wildlife monitoring\n",
        "2. Medical Imaging\n",
        "3. Traffic Data used in self driving cars"
      ],
      "metadata": {
        "id": "NCaTIbad9TWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Object Detection Components**\n",
        "1. Model Architecture\n",
        " * Focus on YOLO (You Only Look Once)\n",
        "2. Pretrained models\n",
        " * Fixed architecture\n",
        " * Pretrained weights for common objects\n",
        "3. Training Custom models\n",
        " * For custom classes\n",
        " * Need labeled data\n",
        " * Define loss function for the multiple parts of objects detection"
      ],
      "metadata": {
        "id": "lfD8bGKE9VUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Traffic Data as Images and Video"
      ],
      "metadata": {
        "id": "qZN6hzby6Xv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QghZqFeQ8pgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Working with image and video data for object detection. We'll explore the specific traffic dataset for this project. The focus will be on how video data can be converted to images, understanding bounding boxes for object classification, and using XML annotations to represent those bounding boxes."
      ],
      "metadata": {
        "id": "H8tpDwQ96g7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objectives:**\n",
        "\n",
        "* Load and organize the project dataset, separating images and their corresponding XML annotations.\n",
        "* Extract frames from a video at regular intervals.\n",
        "* Parse XML annotations.\n",
        "* Visualize bounding boxes on image data."
      ],
      "metadata": {
        "id": "UP2n8lUgAKYX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi27yx676Lo_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Up"
      ],
      "metadata": {
        "id": "rOEySA9JAghf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import xml.etree.ElementTree as ET\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pytubefix\n",
        "from pytubefix import YouTube\n",
        "from IPython.display import Video\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchvision.utils import draw_bounding_boxes, make_grid"
      ],
      "metadata": {
        "id": "XOdvpa_LBdSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Platform:\", sys.platform)\n",
        "print(\"Python version:\", sys.version)\n",
        "print(\"---\")\n",
        "print(\"CV2 version : \", cv2.__version__)\n",
        "print(\"torch version : \", torch.__version__)\n",
        "print(\"torchvision version : \", torchvision.__version__)"
      ],
      "metadata": {
        "id": "pLMOQXa4Bhf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " We are ready to start looking at the data. üèéÔ∏èüí®"
      ],
      "metadata": {
        "id": "R34_MsWSBpBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring Our Data"
      ],
      "metadata": {
        "id": "LNP-CJz6BtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we'll work with two datasets. Let's start with the [Dhaka AI dataset](https://www.kaggle.com/datasets/rifat963/dhakaai-dhaka-based-traffic-detection-dataset), which contains images of vehicles in urban traffic scenes from Dhaka, Bangladesh. This dataset is particularly interesting for computer vision as it captures the unique characteristics of Dhaka's busy streets, including a diverse mix of vehicle types and dense traffic conditions.\n",
        "\n",
        "We'll use the dataset for object detection which is a more complex task than image classification. Object detection identifies specific objects within an image (e.g., cars, buses, motorcycles), determines the precise location of these objects, and draws a bounding box around each detected object.\n",
        "\n",
        "This dataset will be used in a later lesson to create a custom model. For now, we'll begin by exploring the dataset."
      ],
      "metadata": {
        "id": "AoSrcSBGBwUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3.2.1:** Create a variable for the train directory using `pathlib` syntax."
      ],
      "metadata": {
        "id": "MTOMJW7dFBTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dhaka_image_dir = Path(\"data_images\", \"train\")\n",
        "\n",
        "print(\"Data directory:\", dhaka_image_dir)\n",
        "\n",
        "#output\n",
        "Data directory: data_images/train\n"
      ],
      "metadata": {
        "id": "PGd49gEDJgNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's examine some of the contents of the train directory. You'll see two types of files:\n",
        "\n",
        "1. `.xml` files: These contain the annotations for the images.\n",
        "2. `.jpg` files: These are the actual image files.\n",
        "\n",
        "Each image typically has a corresponding XML file."
      ],
      "metadata": {
        "id": "gi7hB6InKCeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dhaka_files = list(dhaka_image_dir.iterdir())\n",
        "dhaka_files[-5:]\n",
        "\n",
        "# Output\n",
        "[PosixPath('data_images/train/Dipto_442.xml'),\n",
        " PosixPath('data_images/train/Numan_(56).jpg'),\n",
        " PosixPath('data_images/train/Navid_323.xml'),\n",
        " PosixPath('data_images/train/Navid_97.jpg'),\n",
        " PosixPath('data_images/train/Navid_181.jpg')]"
      ],
      "metadata": {
        "id": "l2UADsRvKGW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though we only see one type of image file, it turns out that the image files can have many different possible extensions. Let's count the file extensions by type and print the results."
      ],
      "metadata": {
        "id": "oQEQCqsBKkY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_extension_counts = Counter(Path(file).suffix for file in dhaka_files)\n",
        "\n",
        "for extension, count in file_extension_counts.items():\n",
        "    print(f\"Files with extension {extension}: {count}\")\n",
        "\n",
        "# Output\n",
        "Files with extension .xml: 3003\n",
        "Files with extension .jpg: 2844\n",
        "Files with extension .JPG: 143\n",
        "Files with extension .png: 12\n",
        "Files with extension .jpeg: 2\n",
        "Files with extension .PNG: 2"
      ],
      "metadata": {
        "id": "27dte83FKK1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating images and bounding boxes data"
      ],
      "metadata": {
        "id": "8JVqyXLoK5JJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bounding boxes are rectangles around a detected object. All bounding box information is contained in the `.xml` files. The images have several different extensions.   It makes sense to separate the different file types into different folders. We'll want to put all `.xml` files in an annotations folder and the various image types in an images folder."
      ],
      "metadata": {
        "id": "bVdMLbXmLLXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3.2.2:** Create variables for the images and annotations directories using `pathlib` syntax."
      ],
      "metadata": {
        "id": "XyZO_7NgLhuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = dhaka_image_dir / \"images\"\n",
        "annotations_dir = dhaka_image_dir / \"annotations\"\n",
        "\n",
        "images_dir.mkdir(exist_ok=True)\n",
        "annotations_dir.mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "R-0Oo7bvKrPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3.2.3:** Move files to the appropriate directory based on file extensions."
      ],
      "metadata": {
        "id": "cpIDFbKFMIsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in dhaka_files:\n",
        "    if file.suffix.lower() in (\".jpg\", \".jpeg\", \".png\"):\n",
        "        target_dir = images_dir\n",
        "    elif file.suffix.lower() == \".xml\":\n",
        "        target_dir = annotations_dir\n",
        "    file.rename(target_dir / file.name)"
      ],
      "metadata": {
        "id": "8QaMpBWqMb3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's confirm that all the files where moved by making sure there is equal number of images and annotations."
      ],
      "metadata": {
        "id": "PuZJQndXMgeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_files = list(images_dir.iterdir())\n",
        "annotations_files = list(annotations_dir.iterdir())\n",
        "\n",
        "assert len(images_files) == len(annotations_files)"
      ],
      "metadata": {
        "id": "esSw_5dWMosy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}