{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI5so/A9GOkXrx5zCQuV6j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wisdomscode/AI-Lab-Deep-Learning-PyTorch/blob/main/AI_Lab_Project_6_Social_Media_Marketing_at_WQU_6_6_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Ready"
      ],
      "metadata": {
        "id": "6dNwVLKOMV6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll be working with Stable Diffusion, so we'll need to import `diffusers` and `torch`."
      ],
      "metadata": {
        "id": "PU3VS0n_MZsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 6.6.1:** Import `torch` and the `diffusers` modules."
      ],
      "metadata": {
        "id": "ROULxCdNMblT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29zTSejLMKDh"
      },
      "outputs": [],
      "source": [
        "import diffusers\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 6.6.2:** Set the `device` and `dtype` as we did in the lessons."
      ],
      "metadata": {
        "id": "w4N8C8drNVxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    dtype = torch.float16\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    dtype = torch.float32"
      ],
      "metadata": {
        "id": "vEK6dsQYNmqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stable Diffusion"
      ],
      "metadata": {
        "id": "Ly_MABapNojT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll need a Stable Diffusion pipeline to be able to produce images. As we did in the lesson, we'll create a function that returns one."
      ],
      "metadata": {
        "id": "RxX3jtMVNzIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 6.6.3:** Create a function `load_model` that takes no arguments. It should load the Stable Diffusion v1.4 model from Hugging Face and place it on the correct device.  It should return the Stable Diffusion pipeline that gets created."
      ],
      "metadata": {
        "id": "YzBHtiosN0tL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "    MODEL_NAME = \"CompVis/stable-diffusion-v1-4\"\n",
        "    pipeline = diffusers.AutoPipelineForText2Image.from_pretrained(\n",
        "        MODEL_NAME, torch_dtype=dtype\n",
        "    )\n",
        "    return pipeline"
      ],
      "metadata": {
        "id": "6Wme6dF3OzgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = load_model()\n",
        "\n",
        "print(f\"On device {pipeline.device}\")\n",
        "pipeline\n",
        "\n",
        "\n",
        "#output\n",
        "Loading pipeline components...: 100%\n",
        " 7/7 [00:04<00:00,  1.27it/s]\n",
        "On device cpu\n",
        "StableDiffusionPipeline {\n",
        "  \"_class_name\": \"StableDiffusionPipeline\",\n",
        "  \"_diffusers_version\": \"0.32.2\",\n",
        "  \"_name_or_path\": \"CompVis/stable-diffusion-v1-4\",\n",
        "  \"feature_extractor\": [\n",
        "    \"transformers\",\n",
        "    \"CLIPImageProcessor\"\n",
        "  ],\n",
        "  \"image_encoder\": [\n",
        "    null,\n",
        "    null\n",
        "  ],\n",
        "  \"requires_safety_checker\": true,\n",
        "  \"safety_checker\": [\n",
        "    \"stable_diffusion\",\n",
        "    \"StableDiffusionSafetyChecker\"\n",
        "  ],\n",
        "  \"scheduler\": [\n",
        "    \"diffusers\",\n",
        "    \"PNDMScheduler\"\n",
        "  ],\n",
        "  \"text_encoder\": [\n",
        "    \"transformers\",\n",
        "    \"CLIPTextModel\"\n",
        "  ],\n",
        "  \"tokenizer\": [\n",
        "    \"transformers\",\n",
        "    \"CLIPTokenizer\"\n",
        "  ],\n",
        "  \"unet\": [\n",
        "    \"diffusers\",\n",
        "    \"UNet2DConditionModel\"\n",
        "  ],\n",
        "  \"vae\": [\n",
        "    \"diffusers\",\n",
        "    \"AutoencoderKL\"\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "joK_NFUcO0ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll want a function to generate images, as we had before. We'll start with the same one, but we'll expand it as we continue along."
      ],
      "metadata": {
        "id": "J4UHoIsUO9bz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 6.6.4:** Create a function `generate_images(prompt, pipeline, n)`.  It should take three arguments:\n",
        "- `prompt`: An image generation prompt, as a string.\n",
        "- `pipeline`: A Stable Diffusion pipeline object.\n",
        "- `n`: The number of images to create, as an integer.\n",
        "\n",
        "It should return a list of PIL Images of length `n`."
      ],
      "metadata": {
        "id": "pgeFqKdGPEA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(prompt, pipeline, n):\n",
        "    return pipeline([prompt] * n).images"
      ],
      "metadata": {
        "id": "BmnDrgsTPjNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = generate_images(\"Tree with autumn foliage\", pipeline, 2)\n",
        "\n",
        "images[0]"
      ],
      "metadata": {
        "id": "nhCZrWliRbSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a nice starting place. But the `pipeline` takes more arguments, to give users more flexibility with how images are generated. Let's add those in. We'll start with the guidance scale, which we can change with the `guidance_scale` argument in the pipeline."
      ],
      "metadata": {
        "id": "9yhWxuHERaWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 6.6.5:** Change your `generate_images` to also take a `guidance` argument, with a default value of `7.5`. Also change your call to pipeline to include the argument `guidance_scale=guidance`."
      ],
      "metadata": {
        "id": "Q69f7TppRmWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(prompt, pipeline, n, guidance=7.5):\n",
        "    output = pipeline(\n",
        "        [prompt] * n, guidance_scale=guidance\n",
        "    )\n",
        "    return output.images"
      ],
      "metadata": {
        "id": "8_Ac_RxoS4Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = generate_images(\"Tree with autumn foliage\", pipeline, 2, guidance=3.0)\n",
        "\n",
        "images[0]"
      ],
      "metadata": {
        "id": "Se_0RFo0S7yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also change how many steps the model takes, by adjusting the `num_inference_steps` argument to the pipeline. Let's add that as well."
      ],
      "metadata": {
        "id": "nhRi3jDzS-3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 6.6.6:** Change your `generate_images` to also take a `steps` argument, with a default value of `50`. Also change your call to pipeline to include the argument `num_inference_steps=steps`."
      ],
      "metadata": {
        "id": "-Njk7i2oTDRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(prompt, pipeline, n, guidance=7.5, steps=50):\n",
        "    output = pipeline(\n",
        "        [prompt] * n, guidance_scale=guidance, num_inference_steps=steps\n",
        "    )\n",
        "    return output.images"
      ],
      "metadata": {
        "id": "t_FjZst-UGVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = generate_images(\n",
        "    \"Tree with autumn foliage\", pipeline, 2, guidance=7, steps=20\n",
        ")\n",
        "\n",
        "images[0]"
      ],
      "metadata": {
        "id": "3NRaMx7qUHor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are other arguments to the pipeline we could change, but this should be enough for now. We don't want to overwhelm our users (or ourselves)!\n",
        "\n",
        "One thing we saw was that we could add styles. This was actually a somewhat annoying process, so it would be nice for our users if we could do this for them. Here is a dictionary that presents different Stable Diffusion styles along with short names as keys. It'll be handy for the Streamlit app:"
      ],
      "metadata": {
        "id": "wOO-J1EvUacj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "style_dict = {\n",
        "    'none': '',\n",
        "    'anime': 'cartoon, animated, Studio Ghibli style, cute, Japanese animation',\n",
        "    'photo': 'photograph, film, 35 mm camera',\n",
        "    'video game': 'rendered in unreal engine, hyper-realistic, volumetric lighting, --ar 9:16 --hd --q 2',\n",
        "    'watercolor': 'painting, watercolors, pastel, composition'\n",
        "}\n"
      ],
      "metadata": {
        "id": "F6TFJj-oUe8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we should adjust our `generate_images` to take the style name, and add the style string to the prompt. Later, our user will be able to select the nice short name and our app will take care of the rest."
      ],
      "metadata": {
        "id": "kTmQPYHeUnsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 6.6.7:** Change your `generate_images` to also take a `style` argument, with a default value of `\"none\"`. In the function, look up the style string based on the `style` argument, and add that string to the prompt"
      ],
      "metadata": {
        "id": "ROrIgpc2UpvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(prompt, pipeline, n, guidance=7.5, steps=50, style=\"none\"):\n",
        "    style_text = style_dict[style]\n",
        "    output = pipeline(\n",
        "        [prompt + style_text] * n, guidance_scale=guidance, num_inference_steps=steps\n",
        "    )\n",
        "    return output.images"
      ],
      "metadata": {
        "id": "RKC3y7KoV_u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = generate_images(\n",
        "    \"Tree with autumn foliage\", pipeline, 2, steps=20, style=\"anime\"\n",
        ")\n",
        "\n",
        "images[0]"
      ],
      "metadata": {
        "id": "DnDfdxCdWBE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Streamlit App"
      ],
      "metadata": {
        "id": "7pHh3nkFWDmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You have successfully customized Stable Diffusion. Now it's time to create a Streamlit app that will present this to any user.\n",
        "\n",
        "> **The rest of this lesson is entirely optional and it's not graded.**"
      ],
      "metadata": {
        "id": "2xoxE1r2WTg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open the app script located in `app.py` and fill in the code that you have created during this lesson: the imports, the `device` and `dtype` and the functions.\n",
        "\n",
        "You'll find that we have already created a `main()` function that will use your function's parameters.\n",
        "\n",
        "Once you're ready to try it out, run the following in a terminal:"
      ],
      "metadata": {
        "id": "AaD1t505WUXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```bash\n",
        "streamlit run app.py --browser.serverAddress 0.0.0.0 --server.port 9000\n",
        "```"
      ],
      "metadata": {
        "id": "Eqj2GY7SWYGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use the tab switcher to go to the `Streamlit App` tab."
      ],
      "metadata": {
        "id": "0h4lzmHeWZ-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in app.py\n",
        "\n",
        "# import needed libraries\n",
        "import diffusers\n",
        "import torch\n",
        "\n",
        "\n",
        "# Set the device and `dtype` for GPUs\n",
        "\n",
        "# The dictionary mapping style names to style strings\n",
        "style_dict = {\n",
        "    \"none\": \"\",\n",
        "    \"anime\": \"cartoon, animated, Studio Ghibli style, cute, Japanese animation\",\n",
        "    # A photograph on film suggests an artistic approach\n",
        "    \"photo\": \"photograph, film, 35 mm camera\",\n",
        "    \"video game\": \"rendered in unreal engine, hyper-realistic, volumetric lighting, --ar 9:16 --hd --q 2\",\n",
        "    \"watercolor\": \"painting, watercolors, pastel, composition\",\n",
        "}\n",
        "\n",
        "# Load Stable Diffusion (load_model function)\n",
        "def load_model():\n",
        "    MODEL_NAME = \"CompVis/stable-diffusion-v1-4\"\n",
        "    pipeline = diffusers.AutoPipelineForText2Image.from_pretrained(\n",
        "        MODEL_NAME\n",
        "    )\n",
        "    return pipeline\n",
        "\n",
        "\n",
        "# The generate_images function\n",
        "def generate_images(prompt, pipeline, n, guidance=7.5, steps=50, style=\"none\"):\n",
        "    style_text = style_dict[style]\n",
        "    output = pipeline(\n",
        "        [prompt + style_text] * n, guidance_scale=guidance, num_inference_steps=steps\n",
        "    )\n",
        "    return output.images\n",
        "\n",
        "\n",
        "# The main function\n",
        "def main():\n",
        "    st.title(\"Stable Diffusion GUI\")\n",
        "\n",
        "    num_images = st.sidebar.number_input(\"Number of Images\", min_value=1, max_value=10)\n",
        "    prompt = st.sidebar.text_area(\"Text-to-Image Prompt\")\n",
        "\n",
        "    guidance_help = \"Lower values follow the prompt less strictly. Higher values risk distored images.\"\n",
        "    guidance = st.sidebar.slider(\"Guidance\", 2.0, 15.0, 7.5, help=guidance_help)\n",
        "\n",
        "    steps_help = \"More steps produces better images but takes longer.\"\n",
        "    steps = st.sidebar.slider(\"Steps\", 10, 150, 50, help=steps_help)\n",
        "\n",
        "    style = st.sidebar.selectbox(\"Style\", options=style_dict.keys())\n",
        "\n",
        "    generate = st.sidebar.button(\"Generate Images\")\n",
        "    if generate:\n",
        "        with st.spinner(\"Generating images...\"):\n",
        "            pipeline = load_model()\n",
        "            images = generate_images(\n",
        "                prompt, pipeline, num_images, guidance, steps, style\n",
        "            )\n",
        "            for im in images:\n",
        "                st.image(im)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "qUhv0ujbXG-8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}